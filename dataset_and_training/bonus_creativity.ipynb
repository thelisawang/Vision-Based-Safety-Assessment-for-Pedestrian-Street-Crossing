{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fc62ea8-41ea-400d-8d3f-569d91d5bbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n",
      "torch: 2.9.1\n",
      "torchvision: 0.24.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    ")\n",
    "print(\"device:\", device)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c07e1f7-33b3-49c2-8404-588bab48046e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT_DIR: /Users/lisawang/Cornell/25Fall/AML/final/Vision-Based-Safety-Assessment-for-Pedestrian-Street-Crossing/4-dataset_and_training/out_methods_bonus\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH = \"final_data_new_labels.csv\"\n",
    "IMAGES_ROOT = \"processed_data\"\n",
    "\n",
    "OUT_DIR = Path(\"out_methods_bonus\")\n",
    "(OUT_DIR / \"checkpoints\").mkdir(parents=True, exist_ok=True)\n",
    "(OUT_DIR / \"tables\").mkdir(parents=True, exist_ok=True)\n",
    "(OUT_DIR / \"logs\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "assert os.path.isfile(CSV_PATH)\n",
    "assert os.path.isdir(IMAGES_ROOT)\n",
    "\n",
    "print(\"OUT_DIR:\", OUT_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "589b8374-1bea-4cf3-a4aa-21c031dce937",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PedXingDataset(Dataset):\n",
    "    def __init__(self, csv_path, images_root, subset,\n",
    "                 image_size=224, preprocess_mode=\"norm\",\n",
    "                 augment_mode=\"none\", roadway_bin_size_m=5.0):\n",
    "        super().__init__()\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.df = self.df[self.df[\"subset\"] == subset].reset_index(drop=True)\n",
    "\n",
    "        self.images_root = images_root\n",
    "        self.image_size = image_size\n",
    "        self.preprocess_mode = preprocess_mode\n",
    "        self.augment_mode = augment_mode\n",
    "        self.roadway_bin_size_m = roadway_bin_size_m\n",
    "\n",
    "        self.col_filename = \"new_filename\" if \"new_filename\" in self.df.columns else \"filename\"\n",
    "        if \"safe_to_walk\" in self.df.columns:\n",
    "            self.col_safe = \"safe_to_walk\"\n",
    "        elif \"safe_to_cross\" in self.df.columns:\n",
    "            self.col_safe = \"safe_to_cross\"\n",
    "        else:\n",
    "            raise ValueError(\"Missing safe label\")\n",
    "\n",
    "        self.col_weather = \"weather\" if \"weather\" in self.df.columns else None\n",
    "        self.col_tlight = \"traffic_light\" if \"traffic_light\" in self.df.columns else None\n",
    "        if \"crosswalk_signal\" in self.df.columns:\n",
    "            self.col_psignal = \"crosswalk_signal\"\n",
    "        elif \"pedestrian_signal\" in self.df.columns:\n",
    "            self.col_psignal = \"pedestrian_signal\"\n",
    "        else:\n",
    "            self.col_psignal = None\n",
    "\n",
    "        self.col_roadway = \"roadway_width\" if \"roadway_width\" in self.df.columns else None\n",
    "\n",
    "        self.col_crosswalk = \"crosswalk\" if \"crosswalk\" in self.df.columns else None\n",
    "        self.col_car = \"car\" if \"car\" in self.df.columns else None\n",
    "        self.col_scooter = \"scooter\" if \"scooter\" in self.df.columns else None\n",
    "        self.col_bike = \"bike\" if \"bike\" in self.df.columns else None\n",
    "        self.col_obstacles = \"other_obstacles\" if \"other_obstacles\" in self.df.columns else None\n",
    "\n",
    "        self.transform = self._build_transform()\n",
    "\n",
    "    def _build_transform(self):\n",
    "        base = [\n",
    "            T.Resize(self.image_size, antialias=True),\n",
    "            T.CenterCrop(self.image_size),\n",
    "        ]\n",
    "\n",
    "        if self.augment_mode == \"none\":\n",
    "            aug = []\n",
    "            geom = base\n",
    "        elif self.augment_mode == \"basic\":\n",
    "            aug = [\n",
    "                T.RandomResizedCrop(self.image_size, scale=(0.85, 1.0), antialias=True),\n",
    "                T.RandomHorizontalFlip(p=0.5),\n",
    "            ]\n",
    "            geom = []\n",
    "        elif self.augment_mode == \"strong\":\n",
    "            aug = [\n",
    "                T.RandomResizedCrop(self.image_size, scale=(0.75, 1.0), antialias=True),\n",
    "                T.RandomHorizontalFlip(p=0.5),\n",
    "                T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.15, hue=0.02),\n",
    "            ]\n",
    "            geom = []\n",
    "        else:\n",
    "            raise ValueError(\"augment_mode must be none/basic/strong\")\n",
    "\n",
    "        to_tensor = [T.ToTensor()]\n",
    "        if self.preprocess_mode == \"norm\":\n",
    "            norm = [T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])]\n",
    "        elif self.preprocess_mode == \"no_norm\":\n",
    "            norm = []\n",
    "        else:\n",
    "            raise ValueError(\"preprocess_mode must be norm/no_norm\")\n",
    "\n",
    "        return T.Compose(geom + aug + to_tensor + norm)\n",
    "\n",
    "    def _roadway_width_to_bin(self, w):\n",
    "        try:\n",
    "            w = float(w)\n",
    "        except Exception:\n",
    "            return -1\n",
    "        if not np.isfinite(w) or w < 0:\n",
    "            return -1\n",
    "        return int(math.floor(w / self.roadway_bin_size_m))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        fname = str(row[self.col_filename])\n",
    "        img = Image.open(os.path.join(self.images_root, fname)).convert(\"RGB\")\n",
    "        x = self.transform(img)\n",
    "\n",
    "        y = {\"safe_to_cross\": torch.tensor(int(row[self.col_safe]), dtype=torch.long)}\n",
    "\n",
    "        if self.col_weather is not None:\n",
    "            y[\"weather\"] = torch.tensor(int(row[self.col_weather]), dtype=torch.long)\n",
    "        if self.col_psignal is not None:\n",
    "            y[\"pedestrian_signal\"] = torch.tensor(int(row[self.col_psignal]), dtype=torch.long)\n",
    "        if self.col_tlight is not None:\n",
    "            y[\"traffic_light\"] = torch.tensor(int(row[self.col_tlight]), dtype=torch.long)\n",
    "        if self.col_roadway is not None:\n",
    "            y[\"roadway_width_bin\"] = torch.tensor(self._roadway_width_to_bin(row[self.col_roadway]), dtype=torch.long)\n",
    "\n",
    "        def add_bin(col, key):\n",
    "            if col is None: return\n",
    "            y[key] = torch.tensor(int(row[col]), dtype=torch.long)\n",
    "\n",
    "        add_bin(self.col_crosswalk, \"crosswalk\")\n",
    "        add_bin(self.col_car, \"car\")\n",
    "        add_bin(self.col_scooter, \"scooter\")\n",
    "        add_bin(self.col_bike, \"bike\")\n",
    "        add_bin(self.col_obstacles, \"other_obstacles\")\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65b11beb-12a0-4d45-87e1-0efbcd2e862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(subset, image_size, preprocess_mode, augment_mode, batch_size=16, shuffle=True):\n",
    "    ds = PedXingDataset(CSV_PATH, IMAGES_ROOT, subset, image_size=image_size,\n",
    "                       preprocess_mode=preprocess_mode, augment_mode=augment_mode)\n",
    "    use_pin = torch.cuda.is_available()\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle, num_workers=0, pin_memory=use_pin)\n",
    "\n",
    "def infer_roadway_num_classes(train_ds: PedXingDataset) -> int:\n",
    "    if train_ds.col_roadway is None:\n",
    "        return 1\n",
    "    bins = []\n",
    "    for i in range(len(train_ds.df)):\n",
    "        b = train_ds._roadway_width_to_bin(train_ds.df.iloc[i][train_ds.col_roadway])\n",
    "        if b >= 0:\n",
    "            bins.append(b)\n",
    "    return int(max(bins) + 1) if len(bins) else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b6ba3d9-fd29-4640-9352-3a28dae7b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBackbone(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        weights = torchvision.models.ResNet18_Weights.DEFAULT if pretrained else None\n",
    "        m = torchvision.models.resnet18(weights=weights, progress=False)\n",
    "        self.features = nn.Sequential(*list(m.children())[:-1])\n",
    "        self.feat_dim = 512\n",
    "    def forward(self, x):\n",
    "        return self.features(x).flatten(1)\n",
    "\n",
    "class MLPHead(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim=256, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, out_dim),\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "class MultiTaskResNet(nn.Module):\n",
    "    def __init__(self, roadway_num_classes, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.backbone = ResNetBackbone(pretrained=pretrained)\n",
    "        d = self.backbone.feat_dim\n",
    "        self.heads = nn.ModuleDict({\n",
    "            \"safe_to_cross\": MLPHead(d, 2),\n",
    "            \"weather\": MLPHead(d, 3),\n",
    "            \"pedestrian_signal\": MLPHead(d, 3),\n",
    "            \"traffic_light\": MLPHead(d, 3),\n",
    "            \"roadway_width_bin\": MLPHead(d, roadway_num_classes),\n",
    "            \"crosswalk\": MLPHead(d, 2),\n",
    "            \"car\": MLPHead(d, 2),\n",
    "            \"scooter\": MLPHead(d, 2),\n",
    "            \"bike\": MLPHead(d, 2),\n",
    "            \"other_obstacles\": MLPHead(d, 2),\n",
    "        })\n",
    "    def forward(self, x):\n",
    "        z = self.backbone(x)\n",
    "        return {k: h(z) for k, h in self.heads.items()}\n",
    "\n",
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, roadway_num_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, stride=2, padding=2), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "        )\n",
    "        d = 128\n",
    "        self.heads = nn.ModuleDict({\n",
    "            \"safe_to_cross\": nn.Linear(d, 2),\n",
    "            \"weather\": nn.Linear(d, 3),\n",
    "            \"pedestrian_signal\": nn.Linear(d, 3),\n",
    "            \"traffic_light\": nn.Linear(d, 3),\n",
    "            \"roadway_width_bin\": nn.Linear(d, roadway_num_classes),\n",
    "            \"crosswalk\": nn.Linear(d, 2),\n",
    "            \"car\": nn.Linear(d, 2),\n",
    "            \"scooter\": nn.Linear(d, 2),\n",
    "            \"bike\": nn.Linear(d, 2),\n",
    "            \"other_obstacles\": nn.Linear(d, 2),\n",
    "        })\n",
    "    def forward(self, x):\n",
    "        z = self.features(x).flatten(1)\n",
    "        return {k: h(z) for k, h in self.heads.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "076ab7ad-1468-4271-8155-8ee94955b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_from_logits(logits, y):\n",
    "    return (logits.argmax(1) == y).float().mean().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_safe(model, loader):\n",
    "    model.eval()\n",
    "    accs = []\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = {k: v.to(device) for k, v in y.items()}\n",
    "        out = model(x)\n",
    "        accs.append(accuracy_from_logits(out[\"safe_to_cross\"], y[\"safe_to_cross\"]))\n",
    "    return float(np.mean(accs)) if accs else float(\"nan\")\n",
    "\n",
    "def compute_loss(out, y, weights):\n",
    "    total = 0.0\n",
    "    def add(key):\n",
    "        nonlocal total\n",
    "        if key not in out or key not in y:\n",
    "            return\n",
    "        yy = y[key]\n",
    "        if key == \"roadway_width_bin\":\n",
    "            mask = yy >= 0\n",
    "            if mask.sum().item() == 0:\n",
    "                return\n",
    "            logits = out[key][mask]\n",
    "            target = yy[mask]\n",
    "        else:\n",
    "            logits = out[key]\n",
    "            target = yy\n",
    "        total = total + weights.get(key, 0.0) * F.cross_entropy(logits, target)\n",
    "    for k in [\"safe_to_cross\",\"weather\",\"pedestrian_signal\",\"traffic_light\",\"roadway_width_bin\",\n",
    "              \"crosswalk\",\"car\",\"scooter\",\"bike\",\"other_obstacles\"]:\n",
    "        add(k)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32b87c50-e0a1-4257-b336-7a8139d713db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ExpConfig:\n",
    "    exp_name: str\n",
    "    model_family: str          # \"resnet\" or \"smallcnn\"\n",
    "    preprocess_mode: str       # \"norm\"\n",
    "    augment_mode: str          # \"basic\" or \"strong\"\n",
    "    pretrained: bool = True\n",
    "    image_size: int = 224\n",
    "    epochs: int = 20\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-4\n",
    "\n",
    "def run_one(cfg: ExpConfig) -> Dict[str, Any]:\n",
    "    train_loader = make_loader(\"train\", cfg.image_size, cfg.preprocess_mode, cfg.augment_mode, shuffle=True)\n",
    "    val_loader = make_loader(\"val\", cfg.image_size, cfg.preprocess_mode, \"none\", shuffle=False)\n",
    "    test_loader = make_loader(\"test\", cfg.image_size, cfg.preprocess_mode, \"none\", shuffle=False)\n",
    "\n",
    "    roadway_num_classes = infer_roadway_num_classes(train_loader.dataset)\n",
    "\n",
    "    if cfg.model_family == \"resnet\":\n",
    "        model = MultiTaskResNet(roadway_num_classes, pretrained=cfg.pretrained).to(device)\n",
    "    elif cfg.model_family == \"smallcnn\":\n",
    "        model = SmallCNN(roadway_num_classes).to(device)\n",
    "    else:\n",
    "        raise ValueError(\"bad model_family\")\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=cfg.epochs)\n",
    "\n",
    "    weights = {\n",
    "        \"safe_to_cross\": 1.0, \"weather\": 0.3, \"pedestrian_signal\": 0.5, \"traffic_light\": 0.5,\n",
    "        \"roadway_width_bin\": 0.3, \"crosswalk\": 0.2, \"car\": 0.2, \"scooter\": 0.2, \"bike\": 0.2, \"other_obstacles\": 0.2,\n",
    "    }\n",
    "\n",
    "    best = -1.0\n",
    "    ckpt_path = OUT_DIR / \"checkpoints\" / f\"{cfg.exp_name}.pt\"\n",
    "    hist = []\n",
    "\n",
    "    for epoch in range(cfg.epochs):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device)\n",
    "            y = {k: v.to(device) for k, v in y.items()}\n",
    "            out = model(x)\n",
    "            L = compute_loss(out, y, weights)\n",
    "            opt.zero_grad()\n",
    "            L.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            opt.step()\n",
    "            losses.append(float(L.item()))\n",
    "        sched.step()\n",
    "\n",
    "        val_acc = evaluate_safe(model, val_loader)\n",
    "        hist.append({\"exp_name\": cfg.exp_name, \"epoch\": epoch, \"train_loss\": float(np.mean(losses)),\n",
    "                     \"val_safe_acc\": float(val_acc), \"lr\": float(sched.get_last_lr()[0])})\n",
    "\n",
    "        if val_acc > best:\n",
    "            best = val_acc\n",
    "            torch.save({\"cfg\": asdict(cfg), \"state_dict\": model.state_dict(),\n",
    "                        \"roadway_num_classes\": roadway_num_classes}, ckpt_path)\n",
    "\n",
    "        print(f\"[{cfg.exp_name}] epoch={epoch} val_safe_acc={val_acc:.4f} best={best:.4f}\")\n",
    "\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    test_acc = evaluate_safe(model, test_loader)\n",
    "\n",
    "    hist_df = pd.DataFrame(hist)\n",
    "    hist_csv = OUT_DIR / \"logs\" / f\"{cfg.exp_name}_history.csv\"\n",
    "    hist_df.to_csv(hist_csv, index=False)\n",
    "\n",
    "    return {**asdict(cfg),\n",
    "            \"roadway_num_classes\": int(ckpt[\"roadway_num_classes\"]),\n",
    "            \"best_val_safe_acc\": float(best),\n",
    "            \"test_safe_acc\": float(test_acc),\n",
    "            \"ckpt_path\": str(ckpt_path),\n",
    "            \"history_csv\": str(hist_csv)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcc5e2cb-d58f-463f-a6a5-4adcbfdc2bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[B2_finetune_norm_strongaug] epoch=0 val_safe_acc=0.6597 best=0.6597\n",
      "[B2_finetune_norm_strongaug] epoch=1 val_safe_acc=0.5851 best=0.6597\n",
      "[B2_finetune_norm_strongaug] epoch=2 val_safe_acc=0.6007 best=0.6597\n",
      "[B2_finetune_norm_strongaug] epoch=3 val_safe_acc=0.5729 best=0.6597\n",
      "[B2_finetune_norm_strongaug] epoch=4 val_safe_acc=0.7222 best=0.7222\n",
      "[B2_finetune_norm_strongaug] epoch=5 val_safe_acc=0.6354 best=0.7222\n",
      "[B2_finetune_norm_strongaug] epoch=6 val_safe_acc=0.6632 best=0.7222\n",
      "[B2_finetune_norm_strongaug] epoch=7 val_safe_acc=0.6441 best=0.7222\n",
      "[B2_finetune_norm_strongaug] epoch=8 val_safe_acc=0.6944 best=0.7222\n",
      "[B2_finetune_norm_strongaug] epoch=9 val_safe_acc=0.6788 best=0.7222\n",
      "[B2_finetune_norm_strongaug] epoch=10 val_safe_acc=0.7222 best=0.7222\n",
      "[B2_finetune_norm_strongaug] epoch=11 val_safe_acc=0.6944 best=0.7222\n",
      "[B2_finetune_norm_strongaug] epoch=12 val_safe_acc=0.6858 best=0.7222\n",
      "[B2_finetune_norm_strongaug] epoch=13 val_safe_acc=0.7691 best=0.7691\n",
      "[B2_finetune_norm_strongaug] epoch=14 val_safe_acc=0.7569 best=0.7691\n",
      "[B2_finetune_norm_strongaug] epoch=15 val_safe_acc=0.7378 best=0.7691\n",
      "[B2_finetune_norm_strongaug] epoch=16 val_safe_acc=0.7691 best=0.7691\n",
      "[B2_finetune_norm_strongaug] epoch=17 val_safe_acc=0.7413 best=0.7691\n",
      "[B2_finetune_norm_strongaug] epoch=18 val_safe_acc=0.7569 best=0.7691\n",
      "[B2_finetune_norm_strongaug] epoch=19 val_safe_acc=0.7691 best=0.7691\n",
      "[D1_smallcnn_norm_basicaug] epoch=0 val_safe_acc=0.5139 best=0.5139\n",
      "[D1_smallcnn_norm_basicaug] epoch=1 val_safe_acc=0.4861 best=0.5139\n",
      "[D1_smallcnn_norm_basicaug] epoch=2 val_safe_acc=0.4861 best=0.5139\n",
      "[D1_smallcnn_norm_basicaug] epoch=3 val_safe_acc=0.4983 best=0.5139\n",
      "[D1_smallcnn_norm_basicaug] epoch=4 val_safe_acc=0.4427 best=0.5139\n",
      "[D1_smallcnn_norm_basicaug] epoch=5 val_safe_acc=0.5139 best=0.5139\n",
      "[D1_smallcnn_norm_basicaug] epoch=6 val_safe_acc=0.5295 best=0.5295\n",
      "[D1_smallcnn_norm_basicaug] epoch=7 val_safe_acc=0.4705 best=0.5295\n",
      "[D1_smallcnn_norm_basicaug] epoch=8 val_safe_acc=0.4670 best=0.5295\n",
      "[D1_smallcnn_norm_basicaug] epoch=9 val_safe_acc=0.6007 best=0.6007\n",
      "[D1_smallcnn_norm_basicaug] epoch=10 val_safe_acc=0.4826 best=0.6007\n",
      "[D1_smallcnn_norm_basicaug] epoch=11 val_safe_acc=0.4913 best=0.6007\n",
      "[D1_smallcnn_norm_basicaug] epoch=12 val_safe_acc=0.5538 best=0.6007\n",
      "[D1_smallcnn_norm_basicaug] epoch=13 val_safe_acc=0.5538 best=0.6007\n",
      "[D1_smallcnn_norm_basicaug] epoch=14 val_safe_acc=0.5069 best=0.6007\n",
      "[D1_smallcnn_norm_basicaug] epoch=15 val_safe_acc=0.5226 best=0.6007\n",
      "[D1_smallcnn_norm_basicaug] epoch=16 val_safe_acc=0.5226 best=0.6007\n",
      "[D1_smallcnn_norm_basicaug] epoch=17 val_safe_acc=0.4948 best=0.6007\n",
      "[D1_smallcnn_norm_basicaug] epoch=18 val_safe_acc=0.5226 best=0.6007\n",
      "[D1_smallcnn_norm_basicaug] epoch=19 val_safe_acc=0.5069 best=0.6007\n",
      "Saved: out_methods_bonus/tables/results_summary_bonus.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_name</th>\n",
       "      <th>model_family</th>\n",
       "      <th>augment_mode</th>\n",
       "      <th>epochs</th>\n",
       "      <th>lr</th>\n",
       "      <th>best_val_safe_acc</th>\n",
       "      <th>test_safe_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B2_finetune_norm_strongaug</td>\n",
       "      <td>resnet</td>\n",
       "      <td>strong</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.769097</td>\n",
       "      <td>0.800347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D1_smallcnn_norm_basicaug</td>\n",
       "      <td>smallcnn</td>\n",
       "      <td>basic</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.600694</td>\n",
       "      <td>0.595486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     exp_name model_family augment_mode  epochs     lr  \\\n",
       "0  B2_finetune_norm_strongaug       resnet       strong      20  0.001   \n",
       "1   D1_smallcnn_norm_basicaug     smallcnn        basic      20  0.001   \n",
       "\n",
       "   best_val_safe_acc  test_safe_acc  \n",
       "0           0.769097       0.800347  \n",
       "1           0.600694       0.595486  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments = [\n",
    "    ExpConfig(exp_name=\"B2_finetune_norm_strongaug\", model_family=\"resnet\", preprocess_mode=\"norm\", augment_mode=\"strong\", pretrained=True),\n",
    "    ExpConfig(exp_name=\"D1_smallcnn_norm_basicaug\", model_family=\"smallcnn\", preprocess_mode=\"norm\", augment_mode=\"basic\", pretrained=False),\n",
    "]\n",
    "\n",
    "all_results = [run_one(cfg) for cfg in experiments]\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "results_csv = OUT_DIR / \"tables\" / \"results_summary_bonus.csv\"\n",
    "results_df.to_csv(results_csv, index=False)\n",
    "print(\"Saved:\", results_csv)\n",
    "\n",
    "results_df[[\"exp_name\",\"model_family\",\"augment_mode\",\"epochs\",\"lr\",\"best_val_safe_acc\",\"test_safe_acc\"]].sort_values(\"test_safe_acc\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
