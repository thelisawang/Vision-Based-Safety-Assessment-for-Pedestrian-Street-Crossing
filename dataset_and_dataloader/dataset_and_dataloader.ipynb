{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.9.1\n",
      "mps available: True\n",
      "cuda available: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Optional, Sequence, Tuple, Any\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"mps available:\", torch.backends.mps.is_available())\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"final_data_new_labels.csv\"   \n",
    "IMAGES_ROOT = \"processed_data\"           \n",
    "\n",
    "IMAGE_SIZE = 224                         \n",
    "BATCH_SIZE = 16                          \n",
    "NUM_WORKERS = 0                          \n",
    "ROADWAY_BIN_SIZE_M = 5.0                 \n",
    "\n",
    "assert os.path.isfile(CSV_PATH), f\"CSV not found: {CSV_PATH}\"\n",
    "assert os.path.isdir(IMAGES_ROOT), f\"Image folder not found: {IMAGES_ROOT}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pick_col(df: pd.DataFrame, candidates: Sequence[str], required: bool = True) -> Optional[str]:\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    if required:\n",
    "        raise KeyError(f\"Missing required column. Tried: {candidates}. Found: {list(df.columns)}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PedXingColumns:\n",
    "    filename: str\n",
    "    subset: str\n",
    "\n",
    "    safe_to_cross: str\n",
    "    weather: str\n",
    "    roadway_width: str\n",
    "\n",
    "    crosswalk: Optional[str]\n",
    "    pedestrian_signal: Optional[str]\n",
    "    traffic_light: Optional[str]\n",
    "\n",
    "    car: Optional[str]\n",
    "    scooter: Optional[str]\n",
    "    bike: Optional[str]\n",
    "    other_obstacles: Optional[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PedXingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Multi-task dataset for pedestrian crossing scenes.\n",
    "\n",
    "    Returns:\n",
    "        image: torch.FloatTensor [3, H, W]\n",
    "        targets: dict[str, torch.Tensor]  (each value is a scalar tensor)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_path: str,\n",
    "        images_root: str = \"processed_data\",\n",
    "        subset: Optional[str] = None,\n",
    "        image_size: int = 224,\n",
    "        roadway_bin_size_m: float = 5.0,\n",
    "        use_augmentation: bool = False,\n",
    "        normalize_imagenet: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.images_root = images_root\n",
    "        self.subset_filter = subset\n",
    "        self.image_size = image_size\n",
    "        self.roadway_bin_size_m = roadway_bin_size_m\n",
    "\n",
    "        cols = PedXingColumns(\n",
    "            filename=_pick_col(self.df, [\"new_filename\", \"filename\", \"file\", \"image\", \"img\"]),\n",
    "            subset=_pick_col(self.df, [\"subset\", \"split\", \"set\"], required=(subset is not None)),\n",
    "            safe_to_cross=_pick_col(self.df, [\"safe_to_walk\", \"safetowalk\", \"safe_to_cross\", \"safe\"]),\n",
    "            weather=_pick_col(self.df, [\"weather\", \"weather_label\"]),\n",
    "            roadway_width=_pick_col(self.df, [\"roadway_width\", \"width\", \"road_width_m\", \"roadway_width_m\"]),\n",
    "            crosswalk=_pick_col(self.df, [\"crosswalk\", \"zebra_crossing\"], required=False),\n",
    "            pedestrian_signal=_pick_col(self.df, [\"crosswalk_signal\", \"pedestrian_signal\", \"ped_signal\"], required=False),\n",
    "            traffic_light=_pick_col(self.df, [\"traffic_light\", \"traffic_light_state\"], required=False),\n",
    "            car=_pick_col(self.df, [\"car\", \"cars\"], required=False),\n",
    "            scooter=_pick_col(self.df, [\"scooter\", \"scooters\"], required=False),\n",
    "            bike=_pick_col(self.df, [\"bike\", \"bikes\"], required=False),\n",
    "            other_obstacles=_pick_col(self.df, [\"other_obstacles\", \"other_obstacle\", \"obstacles_other\"], required=False),\n",
    "        )\n",
    "        self.cols = cols\n",
    "\n",
    "        if subset is not None:\n",
    "            self.df = self.df[self.df[self.cols.subset].astype(str).str.lower() == str(subset).lower()].reset_index(drop=True)\n",
    "\n",
    "        if len(self.df) == 0:\n",
    "            raise ValueError(f\"No rows found after filtering subset={subset}. Check your CSV subset values.\")\n",
    "\n",
    "        if not os.path.isdir(images_root):\n",
    "            raise FileNotFoundError(f\"images_root directory not found: {images_root}\")\n",
    "\n",
    "        # Transforms\n",
    "        t_list = []\n",
    "        if use_augmentation:\n",
    "            t_list.extend([\n",
    "                T.RandomResizedCrop(image_size, scale=(0.85, 1.0)),\n",
    "                T.RandomHorizontalFlip(p=0.5),\n",
    "            ])\n",
    "        else:\n",
    "            t_list.extend([\n",
    "                T.Resize(int(image_size * 1.14)),\n",
    "                T.CenterCrop(image_size),\n",
    "            ])\n",
    "\n",
    "        t_list.append(T.ToTensor())  # [C,H,W] float in [0,1]\n",
    "\n",
    "        if normalize_imagenet:\n",
    "            t_list.append(T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]))\n",
    "\n",
    "        self.transform = T.Compose(t_list)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def _roadway_width_to_bin(self, width_val: Any) -> int:\n",
    "        if pd.isna(width_val):\n",
    "            return -1\n",
    "\n",
    "        try:\n",
    "            w = float(width_val)\n",
    "        except Exception:\n",
    "            return -1\n",
    "\n",
    "        # If already categorical like 1..8, keep it\n",
    "        if abs(w - round(w)) < 1e-6 and 0 <= w <= 20:\n",
    "            return int(round(w))\n",
    "\n",
    "        # Otherwise assume meters and bin by roadway_bin_size_m\n",
    "        return int(w // self.roadway_bin_size_m)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        fname = str(row[self.cols.filename])\n",
    "        img_path = os.path.join(self.images_root, fname)\n",
    "        if not os.path.isfile(img_path):\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        x = self.transform(img)\n",
    "\n",
    "        def get_optional(col_name: Optional[str]) -> Optional[int]:\n",
    "            if col_name is None:\n",
    "                return None\n",
    "            v = row[col_name]\n",
    "            if pd.isna(v):\n",
    "                return None\n",
    "            return int(v)\n",
    "\n",
    "        targets: Dict[str, torch.Tensor] = {}\n",
    "        targets[\"safe_to_cross\"] = torch.tensor(int(row[self.cols.safe_to_cross]), dtype=torch.long)\n",
    "        targets[\"weather\"] = torch.tensor(int(row[self.cols.weather]), dtype=torch.long)\n",
    "        targets[\"roadway_width_bin\"] = torch.tensor(int(self._roadway_width_to_bin(row[self.cols.roadway_width])), dtype=torch.long)\n",
    "\n",
    "        for key, col in [\n",
    "            (\"crosswalk\", self.cols.crosswalk),\n",
    "            (\"pedestrian_signal\", self.cols.pedestrian_signal),\n",
    "            (\"traffic_light\", self.cols.traffic_light),\n",
    "            (\"car\", self.cols.car),\n",
    "            (\"scooter\", self.cols.scooter),\n",
    "            (\"bike\", self.cols.bike),\n",
    "            (\"other_obstacles\", self.cols.other_obstacles),\n",
    "        ]:\n",
    "            v = get_optional(col)\n",
    "            if v is not None:\n",
    "                targets[key] = torch.tensor(v, dtype=torch.long)\n",
    "\n",
    "        return x, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train batches: 60\n",
      "val batches: 4\n"
     ]
    }
   ],
   "source": [
    "def make_loaders(\n",
    "    csv_path: str,\n",
    "    images_root: str = \"processed_data\",\n",
    "    image_size: int = 224,\n",
    "    batch_size: int = 32,\n",
    "    num_workers: int = 0,\n",
    "):\n",
    "    train_ds = PedXingDataset(\n",
    "        csv_path=csv_path,\n",
    "        images_root=images_root,\n",
    "        subset=\"train\",\n",
    "        image_size=image_size,\n",
    "        roadway_bin_size_m=ROADWAY_BIN_SIZE_M,\n",
    "        use_augmentation=True,\n",
    "    )\n",
    "    val_ds = PedXingDataset(\n",
    "        csv_path=csv_path,\n",
    "        images_root=images_root,\n",
    "        subset=\"val\",\n",
    "        image_size=image_size,\n",
    "        roadway_bin_size_m=ROADWAY_BIN_SIZE_M,\n",
    "        use_augmentation=False,\n",
    "    )\n",
    "\n",
    "    use_pin_memory = torch.cuda.is_available() and (not torch.backends.mps.is_available())\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=use_pin_memory,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=use_pin_memory,\n",
    "    )\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "train_loader, val_loader = make_loaders(\n",
    "    csv_path=CSV_PATH,\n",
    "    images_root=IMAGES_ROOT,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "print(\"train batches:\", len(train_loader))\n",
    "print(\"val batches:\", len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([16, 3, 224, 224])\n",
      "y keys: ['safe_to_cross', 'weather', 'roadway_width_bin', 'crosswalk', 'pedestrian_signal', 'traffic_light', 'car', 'scooter', 'bike', 'other_obstacles']\n",
      "safe_to_cross sample: [0, 1, 1, 0, 1, 1, 0, 1]\n",
      "weather sample: [0, 0, 0, 1, 1, 1, 0, 0]\n",
      "roadway_width_bin sample: [5, 6, 9, 1, 1, 4, 2, 6]\n",
      "missing files in first 50 samples: 0\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "print(\"x shape:\", x.shape)  # expected: [B, 3, H, W]\n",
    "print(\"y keys:\", list(y.keys()))\n",
    "print(\"safe_to_cross sample:\", y[\"safe_to_cross\"][:8].tolist())\n",
    "print(\"weather sample:\", y[\"weather\"][:8].tolist())\n",
    "print(\"roadway_width_bin sample:\", y[\"roadway_width_bin\"][:8].tolist())\n",
    "\n",
    "# Optional: check a few files exist by iterating small number\n",
    "missing = 0\n",
    "for i in range(min(50, len(train_loader.dataset))):\n",
    "    fname = str(train_loader.dataset.df.iloc[i][train_loader.dataset.cols.filename])\n",
    "    if not os.path.isfile(os.path.join(IMAGES_ROOT, fname)):\n",
    "        missing += 1\n",
    "print(\"missing files in first 50 samples:\", missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
