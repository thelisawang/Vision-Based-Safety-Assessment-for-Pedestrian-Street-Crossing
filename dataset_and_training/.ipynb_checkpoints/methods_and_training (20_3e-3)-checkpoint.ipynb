{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef92aaa-56eb-45a8-b38c-353db7744505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.9.1\n",
      "mps available: True\n",
      "cuda available: False\n"
     ]
    }
   ],
   "source": [
    "import os, certifi\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()\n",
    "\n",
    "import math\n",
    "import random\n",
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, Sequence, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"mps available:\", torch.backends.mps.is_available())\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b26c866-f90a-4542-a4c6-5113e7906657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH = \"final_data_new_labels.csv\"\n",
    "IMAGES_ROOT = \"processed_data\"\n",
    "\n",
    "OUT_DIR = Path(\"out_methods\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "CKPT_DIR = OUT_DIR / \"checkpoints\"\n",
    "CKPT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "TABLE_DIR = OUT_DIR / \"tables\"\n",
    "TABLE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "FIG_DIR = OUT_DIR / \"figures\"\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "assert os.path.isfile(CSV_PATH), f\"CSV not found: {CSV_PATH}\"\n",
    "assert os.path.isdir(IMAGES_ROOT), f\"Image folder not found: {IMAGES_ROOT}\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b666e9c0-9e6b-4283-bd9a-2fc664bd7a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 0\n",
    "ROADWAY_BIN_SIZE_M = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae20efd2-f452-47b4-ac75-a319041a947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pick_col(df: pd.DataFrame, candidates: Sequence[str], required: bool = True) -> Optional[str]:\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    if required:\n",
    "        raise KeyError(f\"Missing required column. Tried: {candidates}. Found: {list(df.columns)}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PedXingColumns:\n",
    "    filename: str\n",
    "    subset: str\n",
    "\n",
    "    safe_to_cross: str\n",
    "    weather: str\n",
    "    roadway_width: str\n",
    "\n",
    "    crosswalk: Optional[str]\n",
    "    pedestrian_signal: Optional[str]\n",
    "    traffic_light: Optional[str]\n",
    "\n",
    "    car: Optional[str]\n",
    "    scooter: Optional[str]\n",
    "    bike: Optional[str]\n",
    "    other_obstacles: Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "260e3124-87b2-40ec-abcb-6a2d9b24009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PedXingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Multi-task dataset for pedestrian crossing scenes.\n",
    "\n",
    "    Returns:\n",
    "        image: torch.FloatTensor [3, H, W]\n",
    "        targets: dict[str, torch.Tensor]  (each value is a scalar tensor)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_path: str,\n",
    "        images_root: str = \"processed_data\",\n",
    "        subset: Optional[str] = None,\n",
    "        image_size: int = 224,\n",
    "        roadway_bin_size_m: float = 5.0,\n",
    "        use_augmentation: bool = False,\n",
    "        normalize_imagenet: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.images_root = images_root\n",
    "        self.subset_filter = subset\n",
    "        self.image_size = image_size\n",
    "        self.roadway_bin_size_m = roadway_bin_size_m\n",
    "\n",
    "        cols = PedXingColumns(\n",
    "            filename=_pick_col(self.df, [\"new_filename\", \"filename\", \"file\", \"image\", \"img\"]),\n",
    "            subset=_pick_col(self.df, [\"subset\", \"split\", \"set\"], required=(subset is not None)),\n",
    "            safe_to_cross=_pick_col(self.df, [\"safe_to_walk\", \"safetowalk\", \"safe_to_cross\", \"safe\"]),\n",
    "            weather=_pick_col(self.df, [\"weather\", \"weather_label\"]),\n",
    "            roadway_width=_pick_col(self.df, [\"roadway_width\", \"width\", \"road_width_m\", \"roadway_width_m\"]),\n",
    "            crosswalk=_pick_col(self.df, [\"crosswalk\", \"zebra_crossing\"], required=False),\n",
    "            pedestrian_signal=_pick_col(self.df, [\"crosswalk_signal\", \"pedestrian_signal\", \"ped_signal\"], required=False),\n",
    "            traffic_light=_pick_col(self.df, [\"traffic_light\", \"traffic_light_state\"], required=False),\n",
    "            car=_pick_col(self.df, [\"car\", \"cars\"], required=False),\n",
    "            scooter=_pick_col(self.df, [\"scooter\", \"scooters\"], required=False),\n",
    "            bike=_pick_col(self.df, [\"bike\", \"bikes\"], required=False),\n",
    "            other_obstacles=_pick_col(self.df, [\"other_obstacles\", \"other_obstacle\", \"obstacles_other\"], required=False),\n",
    "        )\n",
    "        self.cols = cols\n",
    "\n",
    "        if subset is not None:\n",
    "            self.df = self.df[self.df[self.cols.subset].astype(str).str.lower() == str(subset).lower()].reset_index(drop=True)\n",
    "\n",
    "        if len(self.df) == 0:\n",
    "            raise ValueError(f\"No rows found after filtering subset={subset}. Check your CSV subset values.\")\n",
    "\n",
    "        if not os.path.isdir(images_root):\n",
    "            raise FileNotFoundError(f\"images_root directory not found: {images_root}\")\n",
    "\n",
    "        # Transforms\n",
    "        t_list = []\n",
    "        if use_augmentation:\n",
    "            t_list.extend([\n",
    "                T.RandomResizedCrop(image_size, scale=(0.85, 1.0)),\n",
    "                T.RandomHorizontalFlip(p=0.5),\n",
    "            ])\n",
    "        else:\n",
    "            t_list.extend([\n",
    "                T.Resize(int(image_size * 1.14)),\n",
    "                T.CenterCrop(image_size),\n",
    "            ])\n",
    "\n",
    "        t_list.append(T.ToTensor())  # [C,H,W] float in [0,1]\n",
    "\n",
    "        if normalize_imagenet:\n",
    "            t_list.append(T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]))\n",
    "\n",
    "        self.transform = T.Compose(t_list)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def _roadway_width_to_bin(self, width_val: Any) -> int:\n",
    "        if pd.isna(width_val):\n",
    "            return -1\n",
    "\n",
    "        try:\n",
    "            w = float(width_val)\n",
    "        except Exception:\n",
    "            return -1\n",
    "\n",
    "        # If already categorical like 1..8, keep it\n",
    "        if abs(w - round(w)) < 1e-6 and 0 <= w <= 20:\n",
    "            return int(round(w))\n",
    "\n",
    "        # Otherwise assume meters and bin by roadway_bin_size_m\n",
    "        return int(w // self.roadway_bin_size_m)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        fname = str(row[self.cols.filename])\n",
    "        img_path = os.path.join(self.images_root, fname)\n",
    "        if not os.path.isfile(img_path):\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        x = self.transform(img)\n",
    "\n",
    "        def get_optional(col_name: Optional[str]) -> Optional[int]:\n",
    "            if col_name is None:\n",
    "                return None\n",
    "            v = row[col_name]\n",
    "            if pd.isna(v):\n",
    "                return None\n",
    "            return int(v)\n",
    "\n",
    "        targets: Dict[str, torch.Tensor] = {}\n",
    "        targets[\"safe_to_cross\"] = torch.tensor(int(row[self.cols.safe_to_cross]), dtype=torch.long)\n",
    "        targets[\"weather\"] = torch.tensor(int(row[self.cols.weather]), dtype=torch.long)\n",
    "        targets[\"roadway_width_bin\"] = torch.tensor(int(self._roadway_width_to_bin(row[self.cols.roadway_width])), dtype=torch.long)\n",
    "\n",
    "        for key, col in [\n",
    "            (\"crosswalk\", self.cols.crosswalk),\n",
    "            (\"pedestrian_signal\", self.cols.pedestrian_signal),\n",
    "            (\"traffic_light\", self.cols.traffic_light),\n",
    "            (\"car\", self.cols.car),\n",
    "            (\"scooter\", self.cols.scooter),\n",
    "            (\"bike\", self.cols.bike),\n",
    "            (\"other_obstacles\", self.cols.other_obstacles),\n",
    "        ]:\n",
    "            v = get_optional(col)\n",
    "            if v is not None:\n",
    "                targets[key] = torch.tensor(v, dtype=torch.long)\n",
    "\n",
    "        return x, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab41d7f9-f399-445e-bd69-c09fcacbc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loaders(\n",
    "    csv_path: str,\n",
    "    images_root: str = \"processed_data\",\n",
    "    image_size: int = 224,\n",
    "    batch_size: int = 32,\n",
    "    num_workers: int = 0,\n",
    "):\n",
    "    train_ds = PedXingDataset(\n",
    "        csv_path=csv_path,\n",
    "        images_root=images_root,\n",
    "        subset=\"train\",\n",
    "        image_size=image_size,\n",
    "        roadway_bin_size_m=ROADWAY_BIN_SIZE_M,\n",
    "        use_augmentation=True,\n",
    "    )\n",
    "    val_ds = PedXingDataset(\n",
    "        csv_path=csv_path,\n",
    "        images_root=images_root,\n",
    "        subset=\"val\",\n",
    "        image_size=image_size,\n",
    "        roadway_bin_size_m=ROADWAY_BIN_SIZE_M,\n",
    "        use_augmentation=False,\n",
    "    )\n",
    "\n",
    "    use_pin_memory = torch.cuda.is_available() and (not torch.backends.mps.is_available())\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=use_pin_memory,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=use_pin_memory,\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d3ab8c5-94ac-4e30-b6ad-126869d60a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train batches: 60\n",
      "val batches: 4\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = make_loaders(\n",
    "    csv_path=CSV_PATH,\n",
    "    images_root=IMAGES_ROOT,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "print(\"train batches:\", len(train_loader))\n",
    "print(\"val batches:\", len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7510799a-29e4-4e4f-9228-472a61807a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test batches: 4\n"
     ]
    }
   ],
   "source": [
    "test_ds = PedXingDataset(\n",
    "    csv_path=CSV_PATH,\n",
    "    images_root=IMAGES_ROOT,\n",
    "    subset=\"test\",\n",
    "    image_size=IMAGE_SIZE,\n",
    "    roadway_bin_size_m=ROADWAY_BIN_SIZE_M,\n",
    "    use_augmentation=False,\n",
    ")\n",
    "use_pin_memory = torch.cuda.is_available() and (not torch.backends.mps.is_available())\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=use_pin_memory)\n",
    "print(\"test batches:\", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdbd05cd-8369-4c77-ac70-d8f3c90818a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unlabeled batches: 5\n"
     ]
    }
   ],
   "source": [
    "unlabeled_ds = PedXingDataset(\n",
    "    csv_path=CSV_PATH,\n",
    "    images_root=IMAGES_ROOT,\n",
    "    subset=\"reserved\",                 # treat as unlabeled pool for semi-supervised\n",
    "    image_size=IMAGE_SIZE,\n",
    "    roadway_bin_size_m=ROADWAY_BIN_SIZE_M,\n",
    "    use_augmentation=True,\n",
    ")\n",
    "unlabeled_loader = DataLoader(unlabeled_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=use_pin_memory)\n",
    "print(\"unlabeled batches:\", len(unlabeled_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "459901d6-f2b6-44cb-918b-3a9a7e15fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary tasks (0/1)\n",
    "BINARY_TASKS = [\"safe_to_cross\", \"crosswalk\", \"car\", \"scooter\", \"bike\", \"other_obstacles\"]\n",
    "\n",
    "# Multi-class tasks (0/1/2)\n",
    "MULTICLASS_TASKS = {\n",
    "    \"pedestrian_signal\": 3,   # crosswalk_signal in CSV\n",
    "    \"traffic_light\": 3,\n",
    "    \"weather\": 3,\n",
    "}\n",
    "\n",
    "# Roadway width bin is multi-class, number of bins depends on dataset\n",
    "# We'll infer num_classes dynamically from training data each run.\n",
    "ROADWAY_TASK = \"roadway_width_bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41aa336d-3296-4152-9f3d-735850a2d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_from_logits(logits: torch.Tensor, y: torch.Tensor) -> float:\n",
    "    pred = logits.argmax(dim=1)\n",
    "    return (pred == y).float().mean().item()\n",
    "\n",
    "def macro_f1_from_logits(logits: torch.Tensor, y: torch.Tensor, num_classes: int) -> float:\n",
    "    pred = logits.argmax(dim=1)\n",
    "    f1s = []\n",
    "    for c in range(num_classes):\n",
    "        tp = ((pred == c) & (y == c)).sum().item()\n",
    "        fp = ((pred == c) & (y != c)).sum().item()\n",
    "        fn = ((pred != c) & (y == c)).sum().item()\n",
    "        precision = tp / (tp + fp + 1e-9)\n",
    "        recall = tp / (tp + fn + 1e-9)\n",
    "        f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "        f1s.append(f1)\n",
    "    return float(np.mean(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d18a62f7-d974-443b-a78e-28121ac7b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBackbone(nn.Module):\n",
    "    def __init__(self, name=\"resnet18\", pretrained=True):\n",
    "        super().__init__()\n",
    "        weights = None\n",
    "        if pretrained:\n",
    "            if name == \"resnet18\":\n",
    "                weights = torchvision.models.ResNet18_Weights.DEFAULT\n",
    "            elif name == \"resnet50\":\n",
    "                weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "\n",
    "        if name == \"resnet18\":\n",
    "            m = torchvision.models.resnet18(weights=weights)\n",
    "            feat_dim = 512\n",
    "        elif name == \"resnet50\":\n",
    "            m = torchvision.models.resnet50(weights=weights)\n",
    "            feat_dim = 2048\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported backbone\")\n",
    "\n",
    "        # remove final fc\n",
    "        self.features = nn.Sequential(*list(m.children())[:-1])\n",
    "        self.feat_dim = feat_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.features(x)          # [B, C, 1, 1]\n",
    "        return z.flatten(1)           # [B, C]\n",
    "\n",
    "\n",
    "class MultiTaskHead(nn.Module):\n",
    "    def __init__(self, feat_dim: int, hidden_dim: int, out_dim: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(feat_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, out_dim),\n",
    "        )\n",
    "        # Kaiming init for linear layers\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "\n",
    "class PedXingModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Shared backbone + multiple heads.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone_name=\"resnet18\",\n",
    "        pretrained=True,\n",
    "        freeze_backbone=False,\n",
    "        hidden_dim=256,\n",
    "        dropout=0.2,\n",
    "        roadway_num_classes=10,  # will be overwritten after inference\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.backbone = ResNetBackbone(name=backbone_name, pretrained=pretrained)\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        feat_dim = self.backbone.feat_dim\n",
    "\n",
    "        # heads\n",
    "        self.heads = nn.ModuleDict()\n",
    "\n",
    "        # binary heads -> 2-class logits to keep consistent CrossEntropy\n",
    "        for t in BINARY_TASKS:\n",
    "            self.heads[t] = MultiTaskHead(feat_dim, hidden_dim, out_dim=2, dropout=dropout)\n",
    "\n",
    "        for t, k in MULTICLASS_TASKS.items():\n",
    "            self.heads[t] = MultiTaskHead(feat_dim, hidden_dim, out_dim=k, dropout=dropout)\n",
    "\n",
    "        self.heads[ROADWAY_TASK] = MultiTaskHead(feat_dim, hidden_dim, out_dim=roadway_num_classes, dropout=dropout)\n",
    "\n",
    "    def forward(self, x) -> Dict[str, torch.Tensor]:\n",
    "        z = self.backbone(x)\n",
    "        return {k: head(z) for k, head in self.heads.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfe0542d-9890-4ddb-b8c0-d5db14777e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roadway_num_classes: 21\n"
     ]
    }
   ],
   "source": [
    "def infer_roadway_num_classes(ds: PedXingDataset) -> int:\n",
    "    # iterate through df column roadway_width (raw) then apply ds._roadway_width_to_bin\n",
    "    bins = []\n",
    "    for i in range(len(ds.df)):\n",
    "        w = ds.df.iloc[i][ds.cols.roadway_width]\n",
    "        b = ds._roadway_width_to_bin(w)\n",
    "        if b >= 0:\n",
    "            bins.append(b)\n",
    "    if len(bins) == 0:\n",
    "        return 1\n",
    "    return int(max(bins) + 1)\n",
    "\n",
    "roadway_num_classes = infer_roadway_num_classes(train_loader.dataset)\n",
    "print(\"roadway_num_classes:\", roadway_num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb9513eb-b4d4-4588-9f2c-34fcbc9ab40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_supervised_loss(\n",
    "    logits: Dict[str, torch.Tensor],\n",
    "    targets: Dict[str, torch.Tensor],\n",
    "    loss_weights: Dict[str, float],\n",
    ") -> Tuple[torch.Tensor, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Only compute loss for keys that exist in targets.\n",
    "    \"\"\"\n",
    "    losses = {}\n",
    "    total = 0.0\n",
    "\n",
    "    for k, out in logits.items():\n",
    "        if k not in targets:\n",
    "            continue\n",
    "        y = targets[k].to(out.device)\n",
    "\n",
    "        # ignore invalid bins (-1) for roadway\n",
    "        if k == ROADWAY_TASK:\n",
    "            mask = (y >= 0)\n",
    "            if mask.sum().item() == 0:\n",
    "                continue\n",
    "            out = out[mask]\n",
    "            y = y[mask]\n",
    "\n",
    "        L = F.cross_entropy(out, y)\n",
    "        w = loss_weights.get(k, 1.0)\n",
    "        losses[k] = (L.item(), w)\n",
    "        total = total + w * L\n",
    "\n",
    "    return total, {k: v[0] for k, v in losses.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c10679e7-8602-47b5-83dc-510f43a74de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module, loader: DataLoader, roadway_num_classes: int) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    sums = {}\n",
    "    counts = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = {k: v.to(device) for k, v in y.items()}\n",
    "        logits = model(x)\n",
    "\n",
    "        # Safe_to_cross accuracy as primary\n",
    "        if \"safe_to_cross\" in logits and \"safe_to_cross\" in y:\n",
    "            acc = accuracy_from_logits(logits[\"safe_to_cross\"], y[\"safe_to_cross\"])\n",
    "            sums[\"safe_acc\"] = sums.get(\"safe_acc\", 0.0) + acc\n",
    "\n",
    "        # Multi-class macro F1 (optional but helpful)\n",
    "        for t, k in MULTICLASS_TASKS.items():\n",
    "            if t in logits and t in y:\n",
    "                f1 = macro_f1_from_logits(logits[t], y[t], num_classes=k)\n",
    "                sums[f\"{t}_macro_f1\"] = sums.get(f\"{t}_macro_f1\", 0.0) + f1\n",
    "\n",
    "        # roadway bin accuracy\n",
    "        if ROADWAY_TASK in logits and ROADWAY_TASK in y:\n",
    "            yy = y[ROADWAY_TASK]\n",
    "            mask = (yy >= 0)\n",
    "            if mask.sum().item() > 0:\n",
    "                acc = accuracy_from_logits(logits[ROADWAY_TASK][mask], yy[mask])\n",
    "                sums[\"roadway_acc\"] = sums.get(\"roadway_acc\", 0.0) + acc\n",
    "\n",
    "        counts += 1\n",
    "\n",
    "    return {k: v / max(counts, 1) for k, v in sums.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2768e8cd-44db-4391-befe-746da73dc76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainConfig:\n",
    "    method_name: str\n",
    "    backbone: str = \"resnet18\"\n",
    "    pretrained: bool = True\n",
    "    freeze_backbone: bool = False\n",
    "    hidden_dim: int = 256\n",
    "    dropout: float = 0.2\n",
    "\n",
    "    epochs: int = 20\n",
    "    lr: float = 3e-3\n",
    "    weight_decay: float = 1e-4\n",
    "    batch_size: int = BATCH_SIZE\n",
    "\n",
    "    # multi-task weights\n",
    "    w_safe: float = 1.0\n",
    "    w_weather: float = 0.3\n",
    "    w_signal: float = 0.5\n",
    "    w_tlight: float = 0.5\n",
    "    w_roadway: float = 0.3\n",
    "    w_binary_aux: float = 0.2\n",
    "\n",
    "    # semi-supervised\n",
    "    use_semi: bool = False\n",
    "    lambda_u: float = 0.5\n",
    "    pseudo_threshold: float = 0.9\n",
    "\n",
    "def build_loss_weights(cfg: TrainConfig) -> Dict[str, float]:\n",
    "    w = {}\n",
    "    w[\"safe_to_cross\"] = cfg.w_safe\n",
    "    w[\"weather\"] = cfg.w_weather\n",
    "    w[\"pedestrian_signal\"] = cfg.w_signal\n",
    "    w[\"traffic_light\"] = cfg.w_tlight\n",
    "    w[ROADWAY_TASK] = cfg.w_roadway\n",
    "    for t in [\"crosswalk\", \"car\", \"scooter\", \"bike\", \"other_obstacles\"]:\n",
    "        w[t] = cfg.w_binary_aux\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31fb68e3-2d89-422a-a070-67b5d1267a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def make_pseudo_labels(logits_u: torch.Tensor, threshold: float) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    logits_u: [B, C]\n",
    "    return:\n",
    "      y_hat: [B]\n",
    "      mask:  [B] (1 if confidence >= threshold else 0)\n",
    "    \"\"\"\n",
    "    probs = torch.softmax(logits_u, dim=1)\n",
    "    conf, y_hat = probs.max(dim=1)\n",
    "    mask = (conf >= threshold).float()\n",
    "    return y_hat, mask\n",
    "\n",
    "def compute_pseudo_label_loss(\n",
    "    model: nn.Module,\n",
    "    x_u: torch.Tensor,\n",
    "    threshold: float,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Pseudo-label only on primary task safe_to_cross.\n",
    "    \"\"\"\n",
    "    logits = model(x_u)[\"safe_to_cross\"]\n",
    "    y_hat, mask = make_pseudo_labels(logits, threshold=threshold)\n",
    "    if mask.sum().item() == 0:\n",
    "        return torch.tensor(0.0, device=logits.device)\n",
    "    loss_all = F.cross_entropy(logits, y_hat, reduction=\"none\")\n",
    "    return (loss_all * mask).sum() / (mask.sum() + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a906b9a8-6b15-4eaf-b0e8-eebc696ae740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(cfg: TrainConfig) -> Dict[str, Any]:\n",
    "    loss_weights = build_loss_weights(cfg)\n",
    "\n",
    "    model = PedXingModel(\n",
    "        backbone_name=cfg.backbone,\n",
    "        pretrained=cfg.pretrained,\n",
    "        freeze_backbone=cfg.freeze_backbone,\n",
    "        hidden_dim=cfg.hidden_dim,\n",
    "        dropout=cfg.dropout,\n",
    "        roadway_num_classes=roadway_num_classes,\n",
    "    ).to(device)\n",
    "\n",
    "    # optimizer and scheduler\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    opt = torch.optim.AdamW(params, lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=cfg.epochs)\n",
    "\n",
    "    best_val = -1.0\n",
    "    best_path = CKPT_DIR / f\"{cfg.method_name}_best.pt\"\n",
    "\n",
    "    history = []\n",
    "\n",
    "    unlabeled_iter = iter(unlabeled_loader) if cfg.use_semi else None\n",
    "\n",
    "    for epoch in range(cfg.epochs):\n",
    "        model.train()\n",
    "        epoch_losses = []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device)\n",
    "            y = {k: v.to(device) for k, v in y.items()}\n",
    "\n",
    "            logits = model(x)\n",
    "            sup_loss, sup_losses_dict = compute_supervised_loss(logits, y, loss_weights)\n",
    "\n",
    "            total_loss = sup_loss\n",
    "\n",
    "            # semi-supervised: add pseudo-label loss from unlabeled pool\n",
    "            if cfg.use_semi:\n",
    "                try:\n",
    "                    x_u, _ = next(unlabeled_iter)\n",
    "                except StopIteration:\n",
    "                    unlabeled_iter = iter(unlabeled_loader)\n",
    "                    x_u, _ = next(unlabeled_iter)\n",
    "\n",
    "                x_u = x_u.to(device)\n",
    "                u_loss = compute_pseudo_label_loss(model, x_u, threshold=cfg.pseudo_threshold)\n",
    "                total_loss = total_loss + cfg.lambda_u * u_loss\n",
    "            else:\n",
    "                u_loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            total_loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            opt.step()\n",
    "\n",
    "            epoch_losses.append({\n",
    "                \"sup_loss\": float(sup_loss.item()),\n",
    "                \"u_loss\": float(u_loss.item()),\n",
    "                \"total_loss\": float(total_loss.item()),\n",
    "                **{f\"sup_{k}\": float(v) for k, v in sup_losses_dict.items()}\n",
    "            })\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # eval\n",
    "        val_metrics = evaluate(model, val_loader, roadway_num_classes)\n",
    "        train_row = {\n",
    "            \"epoch\": epoch,\n",
    "            \"lr\": scheduler.get_last_lr()[0],\n",
    "            \"train_sup_loss\": float(np.mean([r[\"sup_loss\"] for r in epoch_losses])),\n",
    "            \"train_u_loss\": float(np.mean([r[\"u_loss\"] for r in epoch_losses])),\n",
    "            \"train_total_loss\": float(np.mean([r[\"total_loss\"] for r in epoch_losses])),\n",
    "            **{f\"val_{k}\": v for k, v in val_metrics.items()},\n",
    "        }\n",
    "        history.append(train_row)\n",
    "\n",
    "        # early checkpoint on primary metric\n",
    "        primary = val_metrics.get(\"safe_acc\", -1.0)\n",
    "        if primary > best_val:\n",
    "            best_val = primary\n",
    "            torch.save({\"cfg\": asdict(cfg), \"model\": model.state_dict()}, best_path)\n",
    "\n",
    "        print(f\"[{cfg.method_name}] epoch={epoch} val_safe_acc={val_metrics.get('safe_acc', None)} best={best_val}\")\n",
    "\n",
    "    # load best and test\n",
    "    ckpt = torch.load(best_path, map_location=device)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    test_metrics = evaluate(model, test_loader, roadway_num_classes)\n",
    "\n",
    "    # save history\n",
    "    hist_df = pd.DataFrame(history)\n",
    "    hist_path = TABLE_DIR / f\"{cfg.method_name}_history.csv\"\n",
    "    hist_df.to_csv(hist_path, index=False)\n",
    "\n",
    "    result = {\n",
    "        **asdict(cfg),\n",
    "        \"best_val_safe_acc\": float(best_val),\n",
    "        **{f\"test_{k}\": float(v) for k, v in test_metrics.items()},\n",
    "        \"best_ckpt_path\": str(best_path),\n",
    "        \"history_csv\": str(hist_path),\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abb0bda5-7905-4bd0-b3ac-564b62607675",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    # Supervised baseline 1: frozen backbone linear probe (freeze_backbone=True)\n",
    "    TrainConfig(method_name=\"sup_linear_probe\", freeze_backbone=True, use_semi=False),\n",
    "\n",
    "    # Supervised baseline 2: fine-tune backbone\n",
    "    TrainConfig(method_name=\"sup_finetune\", freeze_backbone=False, use_semi=False),\n",
    "\n",
    "    # Semi-supervised: same as sup_finetune but add unlabeled pseudo-label loss\n",
    "    TrainConfig(method_name=\"semi_pseudolabel\", freeze_backbone=False, use_semi=True, lambda_u=0.5, pseudo_threshold=0.9),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c13bfdf9-8f7a-4b20-bba7-c53099031e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sup_linear_probe] epoch=0 val_safe_acc=0.6041666716337204 best=0.6041666716337204\n",
      "[sup_linear_probe] epoch=1 val_safe_acc=0.6822916716337204 best=0.6822916716337204\n",
      "[sup_linear_probe] epoch=2 val_safe_acc=0.6354166716337204 best=0.6822916716337204\n",
      "[sup_linear_probe] epoch=3 val_safe_acc=0.6510416716337204 best=0.6822916716337204\n",
      "[sup_linear_probe] epoch=4 val_safe_acc=0.6666666716337204 best=0.6822916716337204\n",
      "[sup_linear_probe] epoch=5 val_safe_acc=0.6822916716337204 best=0.6822916716337204\n",
      "[sup_linear_probe] epoch=6 val_safe_acc=0.6545138955116272 best=0.6822916716337204\n",
      "[sup_linear_probe] epoch=7 val_safe_acc=0.7291666716337204 best=0.7291666716337204\n",
      "[sup_linear_probe] epoch=8 val_safe_acc=0.7135416716337204 best=0.7291666716337204\n",
      "[sup_linear_probe] epoch=9 val_safe_acc=0.6979166716337204 best=0.7291666716337204\n",
      "[sup_linear_probe] epoch=10 val_safe_acc=0.6857638955116272 best=0.7291666716337204\n",
      "[sup_linear_probe] epoch=11 val_safe_acc=0.6944444477558136 best=0.7291666716337204\n",
      "[sup_linear_probe] epoch=12 val_safe_acc=0.7100694477558136 best=0.7291666716337204\n",
      "[sup_linear_probe] epoch=13 val_safe_acc=0.7725694477558136 best=0.7725694477558136\n",
      "[sup_linear_probe] epoch=14 val_safe_acc=0.6979166716337204 best=0.7725694477558136\n",
      "[sup_linear_probe] epoch=15 val_safe_acc=0.7256944477558136 best=0.7725694477558136\n",
      "[sup_linear_probe] epoch=16 val_safe_acc=0.7256944477558136 best=0.7725694477558136\n",
      "[sup_linear_probe] epoch=17 val_safe_acc=0.7256944477558136 best=0.7725694477558136\n",
      "[sup_linear_probe] epoch=18 val_safe_acc=0.7725694477558136 best=0.7725694477558136\n",
      "[sup_linear_probe] epoch=19 val_safe_acc=0.7413194477558136 best=0.7725694477558136\n",
      "[sup_finetune] epoch=0 val_safe_acc=0.5451388955116272 best=0.5451388955116272\n",
      "[sup_finetune] epoch=1 val_safe_acc=0.4982638955116272 best=0.5451388955116272\n",
      "[sup_finetune] epoch=2 val_safe_acc=0.5850694477558136 best=0.5850694477558136\n",
      "[sup_finetune] epoch=3 val_safe_acc=0.7135416716337204 best=0.7135416716337204\n",
      "[sup_finetune] epoch=4 val_safe_acc=0.6163194477558136 best=0.7135416716337204\n",
      "[sup_finetune] epoch=5 val_safe_acc=0.6354166716337204 best=0.7135416716337204\n",
      "[sup_finetune] epoch=6 val_safe_acc=0.5173611119389534 best=0.7135416716337204\n",
      "[sup_finetune] epoch=7 val_safe_acc=0.6822916716337204 best=0.7135416716337204\n",
      "[sup_finetune] epoch=8 val_safe_acc=0.7569444477558136 best=0.7569444477558136\n",
      "[sup_finetune] epoch=9 val_safe_acc=0.828125 best=0.828125\n",
      "[sup_finetune] epoch=10 val_safe_acc=0.71875 best=0.828125\n",
      "[sup_finetune] epoch=11 val_safe_acc=0.796875 best=0.828125\n",
      "[sup_finetune] epoch=12 val_safe_acc=0.7690972238779068 best=0.828125\n",
      "[sup_finetune] epoch=13 val_safe_acc=0.734375 best=0.828125\n",
      "[sup_finetune] epoch=14 val_safe_acc=0.796875 best=0.828125\n",
      "[sup_finetune] epoch=15 val_safe_acc=0.8125 best=0.828125\n",
      "[sup_finetune] epoch=16 val_safe_acc=0.78125 best=0.828125\n",
      "[sup_finetune] epoch=17 val_safe_acc=0.765625 best=0.828125\n",
      "[sup_finetune] epoch=18 val_safe_acc=0.765625 best=0.828125\n",
      "[sup_finetune] epoch=19 val_safe_acc=0.765625 best=0.828125\n",
      "[semi_pseudolabel] epoch=0 val_safe_acc=0.5451388955116272 best=0.5451388955116272\n",
      "[semi_pseudolabel] epoch=1 val_safe_acc=0.6319444477558136 best=0.6319444477558136\n",
      "[semi_pseudolabel] epoch=2 val_safe_acc=0.5763888955116272 best=0.6319444477558136\n",
      "[semi_pseudolabel] epoch=3 val_safe_acc=0.5729166716337204 best=0.6319444477558136\n",
      "[semi_pseudolabel] epoch=4 val_safe_acc=0.6753472238779068 best=0.6753472238779068\n",
      "[semi_pseudolabel] epoch=5 val_safe_acc=0.6284722238779068 best=0.6753472238779068\n",
      "[semi_pseudolabel] epoch=6 val_safe_acc=0.7222222238779068 best=0.7222222238779068\n",
      "[semi_pseudolabel] epoch=7 val_safe_acc=0.6076388955116272 best=0.7222222238779068\n",
      "[semi_pseudolabel] epoch=8 val_safe_acc=0.6909722238779068 best=0.7222222238779068\n",
      "[semi_pseudolabel] epoch=9 val_safe_acc=0.6788194477558136 best=0.7222222238779068\n",
      "[semi_pseudolabel] epoch=10 val_safe_acc=0.6597222238779068 best=0.7222222238779068\n",
      "[semi_pseudolabel] epoch=11 val_safe_acc=0.765625 best=0.765625\n",
      "[semi_pseudolabel] epoch=12 val_safe_acc=0.7256944477558136 best=0.765625\n",
      "[semi_pseudolabel] epoch=13 val_safe_acc=0.7100694477558136 best=0.765625\n",
      "[semi_pseudolabel] epoch=14 val_safe_acc=0.7222222238779068 best=0.765625\n",
      "[semi_pseudolabel] epoch=15 val_safe_acc=0.7534722238779068 best=0.765625\n",
      "[semi_pseudolabel] epoch=16 val_safe_acc=0.7100694477558136 best=0.765625\n",
      "[semi_pseudolabel] epoch=17 val_safe_acc=0.7256944477558136 best=0.765625\n",
      "[semi_pseudolabel] epoch=18 val_safe_acc=0.7256944477558136 best=0.765625\n",
      "[semi_pseudolabel] epoch=19 val_safe_acc=0.7413194477558136 best=0.765625\n",
      "Saved: out_methods/tables/results_summary.csv\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "for cfg in experiments:\n",
    "    res = run_experiment(cfg)\n",
    "    all_results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_path = TABLE_DIR / \"results_summary.csv\"\n",
    "results_df.to_csv(results_path, index=False)\n",
    "\n",
    "results_df\n",
    "print(\"Saved:\", results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb7644f-fd38-4ca1-969f-7589cf954ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033636aa-c72f-45da-a7f9-68e70931084a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
