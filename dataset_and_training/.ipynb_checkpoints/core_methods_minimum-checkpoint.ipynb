{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21132cfd-821b-4861-9823-14dc66577ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n",
      "torch: 2.9.1\n",
      "torchvision: 0.24.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    ")\n",
    "print(\"device:\", device)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "932459ef-5c4a-4bd1-98d5-2be03c298e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT_DIR: /Users/lisawang/Cornell/25Fall/AML/final/Vision-Based-Safety-Assessment-for-Pedestrian-Street-Crossing/4-dataset_and_training/out_methods_minimum\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH = \"final_data_new_labels.csv\"\n",
    "IMAGES_ROOT = \"processed_data\"\n",
    "\n",
    "OUT_DIR = Path(\"out_methods_minimum\")\n",
    "(OUT_DIR / \"checkpoints\").mkdir(parents=True, exist_ok=True)\n",
    "(OUT_DIR / \"tables\").mkdir(parents=True, exist_ok=True)\n",
    "(OUT_DIR / \"logs\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "assert os.path.isfile(CSV_PATH), f\"CSV not found: {CSV_PATH}\"\n",
    "assert os.path.isdir(IMAGES_ROOT), f\"Image folder not found: {IMAGES_ROOT}\"\n",
    "\n",
    "print(\"OUT_DIR:\", OUT_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16db37a0-7fb6-467c-83a0-8645b9f9c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PedXingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      x: Tensor [3, H, W]\n",
    "      y: dict of targets (some keys may be absent if column not present)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_path: str,\n",
    "        images_root: str,\n",
    "        subset: str,\n",
    "        image_size: int = 224,\n",
    "        preprocess_mode: str = \"norm\",   # \"norm\" or \"no_norm\"\n",
    "        augment_mode: str = \"none\",      # \"none\" or \"basic\"\n",
    "        roadway_bin_size_m: float = 5.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.df = self.df[self.df[\"subset\"] == subset].reset_index(drop=True)\n",
    "\n",
    "        self.images_root = images_root\n",
    "        self.image_size = image_size\n",
    "        self.preprocess_mode = preprocess_mode\n",
    "        self.augment_mode = augment_mode\n",
    "        self.roadway_bin_size_m = roadway_bin_size_m\n",
    "\n",
    "        self.col_filename = \"new_filename\" if \"new_filename\" in self.df.columns else \"filename\"\n",
    "\n",
    "        if \"safe_to_walk\" in self.df.columns:\n",
    "            self.col_safe = \"safe_to_walk\"\n",
    "        elif \"safe_to_cross\" in self.df.columns:\n",
    "            self.col_safe = \"safe_to_cross\"\n",
    "        else:\n",
    "            raise ValueError(\"Missing safety label column: safe_to_walk or safe_to_cross\")\n",
    "\n",
    "        self.col_weather = \"weather\" if \"weather\" in self.df.columns else None\n",
    "        self.col_tlight = \"traffic_light\" if \"traffic_light\" in self.df.columns else None\n",
    "\n",
    "        if \"crosswalk_signal\" in self.df.columns:\n",
    "            self.col_psignal = \"crosswalk_signal\"\n",
    "        elif \"pedestrian_signal\" in self.df.columns:\n",
    "            self.col_psignal = \"pedestrian_signal\"\n",
    "        else:\n",
    "            self.col_psignal = None\n",
    "\n",
    "        self.col_roadway = \"roadway_width\" if \"roadway_width\" in self.df.columns else None\n",
    "\n",
    "        # binary\n",
    "        self.col_crosswalk = \"crosswalk\" if \"crosswalk\" in self.df.columns else None\n",
    "        self.col_car = \"car\" if \"car\" in self.df.columns else None\n",
    "        self.col_scooter = \"scooter\" if \"scooter\" in self.df.columns else None\n",
    "        self.col_bike = \"bike\" if \"bike\" in self.df.columns else None\n",
    "        self.col_obstacles = \"other_obstacles\" if \"other_obstacles\" in self.df.columns else None\n",
    "\n",
    "        self.transform = self._build_transform()\n",
    "\n",
    "    def _build_transform(self):\n",
    "        base = [\n",
    "            T.Resize(self.image_size, antialias=True),\n",
    "            T.CenterCrop(self.image_size),\n",
    "        ]\n",
    "\n",
    "        aug = []\n",
    "        if self.augment_mode == \"basic\":\n",
    "            aug = [\n",
    "                T.RandomResizedCrop(self.image_size, scale=(0.85, 1.0), antialias=True),\n",
    "                T.RandomHorizontalFlip(p=0.5),\n",
    "            ]\n",
    "        elif self.augment_mode == \"none\":\n",
    "            aug = []\n",
    "        else:\n",
    "            raise ValueError(\"augment_mode must be 'none' or 'basic' in minimum notebook\")\n",
    "\n",
    "        to_tensor = [T.ToTensor()]\n",
    "        if self.preprocess_mode == \"norm\":\n",
    "            norm = [T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])]\n",
    "        elif self.preprocess_mode == \"no_norm\":\n",
    "            norm = []\n",
    "        else:\n",
    "            raise ValueError(\"preprocess_mode must be 'norm' or 'no_norm'\")\n",
    "\n",
    "        if len(aug) > 0:\n",
    "            return T.Compose(aug + to_tensor + norm)\n",
    "        return T.Compose(base + to_tensor + norm)\n",
    "\n",
    "    def _roadway_width_to_bin(self, w: Any) -> int:\n",
    "        try:\n",
    "            w = float(w)\n",
    "        except Exception:\n",
    "            return -1\n",
    "        if not np.isfinite(w) or w < 0:\n",
    "            return -1\n",
    "        return int(math.floor(w / self.roadway_bin_size_m))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        fname = str(row[self.col_filename])\n",
    "        path = os.path.join(self.images_root, fname)\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        x = self.transform(img)\n",
    "\n",
    "        y = {}\n",
    "        y[\"safe_to_cross\"] = torch.tensor(int(row[self.col_safe]), dtype=torch.long)\n",
    "\n",
    "        if self.col_weather is not None:\n",
    "            y[\"weather\"] = torch.tensor(int(row[self.col_weather]), dtype=torch.long)\n",
    "        if self.col_psignal is not None:\n",
    "            y[\"pedestrian_signal\"] = torch.tensor(int(row[self.col_psignal]), dtype=torch.long)\n",
    "        if self.col_tlight is not None:\n",
    "            y[\"traffic_light\"] = torch.tensor(int(row[self.col_tlight]), dtype=torch.long)\n",
    "        if self.col_roadway is not None:\n",
    "            y[\"roadway_width_bin\"] = torch.tensor(self._roadway_width_to_bin(row[self.col_roadway]), dtype=torch.long)\n",
    "\n",
    "        def add_bin(col, key):\n",
    "            if col is None:\n",
    "                return\n",
    "            y[key] = torch.tensor(int(row[col]), dtype=torch.long)\n",
    "\n",
    "        add_bin(self.col_crosswalk, \"crosswalk\")\n",
    "        add_bin(self.col_car, \"car\")\n",
    "        add_bin(self.col_scooter, \"scooter\")\n",
    "        add_bin(self.col_bike, \"bike\")\n",
    "        add_bin(self.col_obstacles, \"other_obstacles\")\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad94d22c-d566-4ffb-81d7-254db7bb7f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(subset: str, image_size: int, preprocess_mode: str, augment_mode: str,\n",
    "                batch_size: int = 16, shuffle: bool = True, roadway_bin_size_m: float = 5.0) -> DataLoader:\n",
    "    ds = PedXingDataset(\n",
    "        csv_path=CSV_PATH,\n",
    "        images_root=IMAGES_ROOT,\n",
    "        subset=subset,\n",
    "        image_size=image_size,\n",
    "        preprocess_mode=preprocess_mode,\n",
    "        augment_mode=augment_mode,\n",
    "        roadway_bin_size_m=roadway_bin_size_m,\n",
    "    )\n",
    "    use_pin_memory = torch.cuda.is_available()\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle, num_workers=0, pin_memory=use_pin_memory)\n",
    "\n",
    "def infer_roadway_num_classes(train_ds: PedXingDataset) -> int:\n",
    "    if train_ds.col_roadway is None:\n",
    "        return 1\n",
    "    bins = []\n",
    "    for i in range(len(train_ds.df)):\n",
    "        b = train_ds._roadway_width_to_bin(train_ds.df.iloc[i][train_ds.col_roadway])\n",
    "        if b >= 0:\n",
    "            bins.append(b)\n",
    "    return int(max(bins) + 1) if len(bins) > 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a47e41a2-ca50-4368-a828-3c8b77b07565",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBackbone(nn.Module):\n",
    "    def __init__(self, pretrained: bool = True):\n",
    "        super().__init__()\n",
    "        weights = torchvision.models.ResNet18_Weights.DEFAULT if pretrained else None\n",
    "        m = torchvision.models.resnet18(weights=weights, progress=False)\n",
    "        self.features = nn.Sequential(*list(m.children())[:-1])\n",
    "        self.feat_dim = 512\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.features(x)\n",
    "        return z.flatten(1)\n",
    "\n",
    "class MLPHead(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int, hidden_dim: int = 256, dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, out_dim),\n",
    "        )\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "class MultiTaskResNet(nn.Module):\n",
    "    def __init__(self, roadway_num_classes: int, pretrained: bool = True, freeze_backbone: bool = False):\n",
    "        super().__init__()\n",
    "        self.backbone = ResNetBackbone(pretrained=pretrained)\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        d = self.backbone.feat_dim\n",
    "        self.heads = nn.ModuleDict({\n",
    "            \"safe_to_cross\": MLPHead(d, 2),\n",
    "            \"weather\": MLPHead(d, 3),\n",
    "            \"pedestrian_signal\": MLPHead(d, 3),\n",
    "            \"traffic_light\": MLPHead(d, 3),\n",
    "            \"roadway_width_bin\": MLPHead(d, roadway_num_classes),\n",
    "            \"crosswalk\": MLPHead(d, 2),\n",
    "            \"car\": MLPHead(d, 2),\n",
    "            \"scooter\": MLPHead(d, 2),\n",
    "            \"bike\": MLPHead(d, 2),\n",
    "            \"other_obstacles\": MLPHead(d, 2),\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.backbone(x)\n",
    "        return {k: head(z) for k, head in self.heads.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2edddde-d25f-4bba-b542-ee7de8f1d68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_from_logits(logits: torch.Tensor, y: torch.Tensor) -> float:\n",
    "    pred = logits.argmax(dim=1)\n",
    "    return (pred == y).float().mean().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module, loader: DataLoader) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    acc_safe = []\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = {k: v.to(device) for k, v in y.items()}\n",
    "        out = model(x)\n",
    "        acc_safe.append(accuracy_from_logits(out[\"safe_to_cross\"], y[\"safe_to_cross\"]))\n",
    "    return {\"safe_acc\": float(np.mean(acc_safe)) if len(acc_safe) else float(\"nan\")}\n",
    "\n",
    "def compute_loss(out: Dict[str, torch.Tensor], y: Dict[str, torch.Tensor], weights: Dict[str, float]) -> torch.Tensor:\n",
    "    total = 0.0\n",
    "\n",
    "    def add_ce(key: str):\n",
    "        nonlocal total\n",
    "        if key not in out or key not in y:\n",
    "            return\n",
    "        yy = y[key]\n",
    "        if key == \"roadway_width_bin\":\n",
    "            mask = yy >= 0\n",
    "            if mask.sum().item() == 0:\n",
    "                return\n",
    "            logits = out[key][mask]\n",
    "            target = yy[mask]\n",
    "        else:\n",
    "            logits = out[key]\n",
    "            target = yy\n",
    "        total = total + weights.get(key, 0.0) * F.cross_entropy(logits, target)\n",
    "\n",
    "    # primary + a few auxiliaries (keep minimal compute)\n",
    "    add_ce(\"safe_to_cross\")\n",
    "    add_ce(\"weather\")\n",
    "    add_ce(\"pedestrian_signal\")\n",
    "    add_ce(\"traffic_light\")\n",
    "    add_ce(\"roadway_width_bin\")\n",
    "    add_ce(\"crosswalk\")\n",
    "    add_ce(\"car\")\n",
    "    add_ce(\"scooter\")\n",
    "    add_ce(\"bike\")\n",
    "    add_ce(\"other_obstacles\")\n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb9e905c-70b5-4ee3-a0fc-50f352d4ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ExpConfig:\n",
    "    exp_name: str\n",
    "    freeze_backbone: bool\n",
    "    preprocess_mode: str       # \"norm\" or \"no_norm\"\n",
    "    augment_mode: str          # \"none\" or \"basic\"\n",
    "    image_size: int = 224\n",
    "    pretrained: bool = True\n",
    "    epochs: int = 20\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-4\n",
    "\n",
    "def run_one(cfg: ExpConfig) -> Dict[str, Any]:\n",
    "    train_loader = make_loader(\"train\", cfg.image_size, cfg.preprocess_mode, cfg.augment_mode, shuffle=True)\n",
    "    val_loader = make_loader(\"val\", cfg.image_size, cfg.preprocess_mode, \"none\", shuffle=False)\n",
    "    test_loader = make_loader(\"test\", cfg.image_size, cfg.preprocess_mode, \"none\", shuffle=False)\n",
    "\n",
    "    roadway_num_classes = infer_roadway_num_classes(train_loader.dataset)\n",
    "\n",
    "    model = MultiTaskResNet(\n",
    "        roadway_num_classes=roadway_num_classes,\n",
    "        pretrained=cfg.pretrained,\n",
    "        freeze_backbone=cfg.freeze_backbone\n",
    "    ).to(device)\n",
    "\n",
    "    opt = torch.optim.AdamW([p for p in model.parameters() if p.requires_grad],\n",
    "                            lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=cfg.epochs)\n",
    "\n",
    "    weights = {\n",
    "        \"safe_to_cross\": 1.0,\n",
    "        \"weather\": 0.3,\n",
    "        \"pedestrian_signal\": 0.5,\n",
    "        \"traffic_light\": 0.5,\n",
    "        \"roadway_width_bin\": 0.3,\n",
    "        \"crosswalk\": 0.2,\n",
    "        \"car\": 0.2,\n",
    "        \"scooter\": 0.2,\n",
    "        \"bike\": 0.2,\n",
    "        \"other_obstacles\": 0.2,\n",
    "    }\n",
    "\n",
    "    best_val = -1.0\n",
    "    ckpt_path = OUT_DIR / \"checkpoints\" / f\"{cfg.exp_name}.pt\"\n",
    "    hist = []\n",
    "\n",
    "    for epoch in range(cfg.epochs):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device)\n",
    "            y = {k: v.to(device) for k, v in y.items()}\n",
    "            out = model(x)\n",
    "            L = compute_loss(out, y, weights)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            L.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            opt.step()\n",
    "\n",
    "            losses.append(float(L.item()))\n",
    "\n",
    "        sched.step()\n",
    "\n",
    "        val_m = evaluate(model, val_loader)\n",
    "        row = {\"exp_name\": cfg.exp_name, \"epoch\": epoch, \"train_loss\": float(np.mean(losses)),\n",
    "               \"val_safe_acc\": float(val_m[\"safe_acc\"]), \"lr\": float(sched.get_last_lr()[0])}\n",
    "        hist.append(row)\n",
    "\n",
    "        if val_m[\"safe_acc\"] > best_val:\n",
    "            best_val = val_m[\"safe_acc\"]\n",
    "            torch.save({\"cfg\": asdict(cfg), \"state_dict\": model.state_dict(),\n",
    "                        \"roadway_num_classes\": roadway_num_classes}, ckpt_path)\n",
    "\n",
    "        print(f\"[{cfg.exp_name}] epoch={epoch} val_safe_acc={val_m['safe_acc']:.4f} best={best_val:.4f}\")\n",
    "\n",
    "    # load best -> test\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    test_m = evaluate(model, test_loader)\n",
    "\n",
    "    hist_df = pd.DataFrame(hist)\n",
    "    hist_csv = OUT_DIR / \"logs\" / f\"{cfg.exp_name}_history.csv\"\n",
    "    hist_df.to_csv(hist_csv, index=False)\n",
    "\n",
    "    return {\n",
    "        **asdict(cfg),\n",
    "        \"roadway_num_classes\": int(ckpt[\"roadway_num_classes\"]),\n",
    "        \"best_val_safe_acc\": float(best_val),\n",
    "        \"test_safe_acc\": float(test_m[\"safe_acc\"]),\n",
    "        \"ckpt_path\": str(ckpt_path),\n",
    "        \"history_csv\": str(hist_csv),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c579cb13-8fcc-4aaa-849f-9a658d8b0002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A1_linearprobe_norm_noaug] epoch=0 val_safe_acc=0.6667 best=0.6667\n",
      "[A1_linearprobe_norm_noaug] epoch=1 val_safe_acc=0.6198 best=0.6667\n",
      "[A1_linearprobe_norm_noaug] epoch=2 val_safe_acc=0.6823 best=0.6823\n",
      "[A1_linearprobe_norm_noaug] epoch=3 val_safe_acc=0.7101 best=0.7101\n",
      "[A1_linearprobe_norm_noaug] epoch=4 val_safe_acc=0.6979 best=0.7101\n",
      "[A1_linearprobe_norm_noaug] epoch=5 val_safe_acc=0.5729 best=0.7101\n",
      "[A1_linearprobe_norm_noaug] epoch=6 val_safe_acc=0.6823 best=0.7101\n",
      "[A1_linearprobe_norm_noaug] epoch=7 val_safe_acc=0.6667 best=0.7101\n",
      "[A1_linearprobe_norm_noaug] epoch=8 val_safe_acc=0.7101 best=0.7101\n",
      "[A1_linearprobe_norm_noaug] epoch=9 val_safe_acc=0.6354 best=0.7101\n",
      "[A1_linearprobe_norm_noaug] epoch=10 val_safe_acc=0.6667 best=0.7101\n",
      "[A1_linearprobe_norm_noaug] epoch=11 val_safe_acc=0.5955 best=0.7101\n",
      "[A1_linearprobe_norm_noaug] epoch=12 val_safe_acc=0.6701 best=0.7101\n",
      "[A1_linearprobe_norm_noaug] epoch=13 val_safe_acc=0.6667 best=0.7101\n",
      "[A1_linearprobe_norm_noaug] epoch=14 val_safe_acc=0.6354 best=0.7101\n",
      "[A1_linearprobe_norm_noaug] epoch=15 val_safe_acc=0.6667 best=0.7101\n",
      "[A1_linearprobe_norm_noaug] epoch=16 val_safe_acc=0.6389 best=0.7101\n",
      "[A1_linearprobe_norm_noaug] epoch=17 val_safe_acc=0.6510 best=0.7101\n",
      "[A1_linearprobe_norm_noaug] epoch=18 val_safe_acc=0.6545 best=0.7101\n",
      "[A1_linearprobe_norm_noaug] epoch=19 val_safe_acc=0.6389 best=0.7101\n",
      "[A2_finetune_norm_noaug] epoch=0 val_safe_acc=0.5330 best=0.5330\n",
      "[A2_finetune_norm_noaug] epoch=1 val_safe_acc=0.5642 best=0.5642\n",
      "[A2_finetune_norm_noaug] epoch=2 val_safe_acc=0.5451 best=0.5642\n",
      "[A2_finetune_norm_noaug] epoch=3 val_safe_acc=0.5642 best=0.5642\n",
      "[A2_finetune_norm_noaug] epoch=4 val_safe_acc=0.6545 best=0.6545\n",
      "[A2_finetune_norm_noaug] epoch=5 val_safe_acc=0.5764 best=0.6545\n",
      "[A2_finetune_norm_noaug] epoch=6 val_safe_acc=0.6632 best=0.6632\n",
      "[A2_finetune_norm_noaug] epoch=7 val_safe_acc=0.6667 best=0.6667\n",
      "[A2_finetune_norm_noaug] epoch=8 val_safe_acc=0.6667 best=0.6667\n",
      "[A2_finetune_norm_noaug] epoch=9 val_safe_acc=0.6701 best=0.6701\n",
      "[A2_finetune_norm_noaug] epoch=10 val_safe_acc=0.7257 best=0.7257\n",
      "[A2_finetune_norm_noaug] epoch=11 val_safe_acc=0.6858 best=0.7257\n",
      "[A2_finetune_norm_noaug] epoch=12 val_safe_acc=0.7257 best=0.7257\n",
      "[A2_finetune_norm_noaug] epoch=13 val_safe_acc=0.6788 best=0.7257\n",
      "[A2_finetune_norm_noaug] epoch=14 val_safe_acc=0.7726 best=0.7726\n",
      "[A2_finetune_norm_noaug] epoch=15 val_safe_acc=0.7760 best=0.7760\n",
      "[A2_finetune_norm_noaug] epoch=16 val_safe_acc=0.7135 best=0.7760\n",
      "[A2_finetune_norm_noaug] epoch=17 val_safe_acc=0.7569 best=0.7760\n",
      "[A2_finetune_norm_noaug] epoch=18 val_safe_acc=0.7257 best=0.7760\n",
      "[A2_finetune_norm_noaug] epoch=19 val_safe_acc=0.7569 best=0.7760\n",
      "[B1_finetune_norm_basicaug] epoch=0 val_safe_acc=0.7222 best=0.7222\n",
      "[B1_finetune_norm_basicaug] epoch=1 val_safe_acc=0.5017 best=0.7222\n",
      "[B1_finetune_norm_basicaug] epoch=2 val_safe_acc=0.6441 best=0.7222\n",
      "[B1_finetune_norm_basicaug] epoch=3 val_safe_acc=0.5642 best=0.7222\n",
      "[B1_finetune_norm_basicaug] epoch=4 val_safe_acc=0.6510 best=0.7222\n",
      "[B1_finetune_norm_basicaug] epoch=5 val_safe_acc=0.7812 best=0.7812\n",
      "[B1_finetune_norm_basicaug] epoch=6 val_safe_acc=0.6823 best=0.7812\n",
      "[B1_finetune_norm_basicaug] epoch=7 val_safe_acc=0.6319 best=0.7812\n",
      "[B1_finetune_norm_basicaug] epoch=8 val_safe_acc=0.6944 best=0.7812\n",
      "[B1_finetune_norm_basicaug] epoch=9 val_safe_acc=0.6944 best=0.7812\n",
      "[B1_finetune_norm_basicaug] epoch=10 val_safe_acc=0.6233 best=0.7812\n",
      "[B1_finetune_norm_basicaug] epoch=11 val_safe_acc=0.6823 best=0.7812\n",
      "[B1_finetune_norm_basicaug] epoch=12 val_safe_acc=0.7448 best=0.7812\n",
      "[B1_finetune_norm_basicaug] epoch=13 val_safe_acc=0.7135 best=0.7812\n",
      "[B1_finetune_norm_basicaug] epoch=14 val_safe_acc=0.6858 best=0.7812\n",
      "[B1_finetune_norm_basicaug] epoch=15 val_safe_acc=0.6545 best=0.7812\n",
      "[B1_finetune_norm_basicaug] epoch=16 val_safe_acc=0.7014 best=0.7812\n",
      "[B1_finetune_norm_basicaug] epoch=17 val_safe_acc=0.7292 best=0.7812\n",
      "[B1_finetune_norm_basicaug] epoch=18 val_safe_acc=0.7135 best=0.7812\n",
      "[B1_finetune_norm_basicaug] epoch=19 val_safe_acc=0.7292 best=0.7812\n",
      "[C1_finetune_nonorm_basicaug] epoch=0 val_safe_acc=0.4861 best=0.4861\n",
      "[C1_finetune_nonorm_basicaug] epoch=1 val_safe_acc=0.4201 best=0.4861\n",
      "[C1_finetune_nonorm_basicaug] epoch=2 val_safe_acc=0.6076 best=0.6076\n",
      "[C1_finetune_nonorm_basicaug] epoch=3 val_safe_acc=0.5330 best=0.6076\n",
      "[C1_finetune_nonorm_basicaug] epoch=4 val_safe_acc=0.6545 best=0.6545\n",
      "[C1_finetune_nonorm_basicaug] epoch=5 val_safe_acc=0.6042 best=0.6545\n",
      "[C1_finetune_nonorm_basicaug] epoch=6 val_safe_acc=0.6510 best=0.6545\n",
      "[C1_finetune_nonorm_basicaug] epoch=7 val_safe_acc=0.6597 best=0.6597\n",
      "[C1_finetune_nonorm_basicaug] epoch=8 val_safe_acc=0.6910 best=0.6910\n",
      "[C1_finetune_nonorm_basicaug] epoch=9 val_safe_acc=0.5851 best=0.6910\n",
      "[C1_finetune_nonorm_basicaug] epoch=10 val_safe_acc=0.7101 best=0.7101\n",
      "[C1_finetune_nonorm_basicaug] epoch=11 val_safe_acc=0.6285 best=0.7101\n",
      "[C1_finetune_nonorm_basicaug] epoch=12 val_safe_acc=0.7378 best=0.7378\n",
      "[C1_finetune_nonorm_basicaug] epoch=13 val_safe_acc=0.5799 best=0.7378\n",
      "[C1_finetune_nonorm_basicaug] epoch=14 val_safe_acc=0.7691 best=0.7691\n",
      "[C1_finetune_nonorm_basicaug] epoch=15 val_safe_acc=0.7413 best=0.7691\n",
      "[C1_finetune_nonorm_basicaug] epoch=16 val_safe_acc=0.7812 best=0.7812\n",
      "[C1_finetune_nonorm_basicaug] epoch=17 val_safe_acc=0.7691 best=0.7812\n",
      "[C1_finetune_nonorm_basicaug] epoch=18 val_safe_acc=0.7847 best=0.7847\n",
      "[C1_finetune_nonorm_basicaug] epoch=19 val_safe_acc=0.7569 best=0.7847\n",
      "Saved: out_methods_minimum/tables/results_summary_min.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_name</th>\n",
       "      <th>freeze_backbone</th>\n",
       "      <th>preprocess_mode</th>\n",
       "      <th>augment_mode</th>\n",
       "      <th>epochs</th>\n",
       "      <th>lr</th>\n",
       "      <th>best_val_safe_acc</th>\n",
       "      <th>test_safe_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2_finetune_norm_noaug</td>\n",
       "      <td>False</td>\n",
       "      <td>norm</td>\n",
       "      <td>none</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.776042</td>\n",
       "      <td>0.744792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1_finetune_nonorm_basicaug</td>\n",
       "      <td>False</td>\n",
       "      <td>no_norm</td>\n",
       "      <td>basic</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.784722</td>\n",
       "      <td>0.717014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1_linearprobe_norm_noaug</td>\n",
       "      <td>True</td>\n",
       "      <td>norm</td>\n",
       "      <td>none</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.710069</td>\n",
       "      <td>0.710069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B1_finetune_norm_basicaug</td>\n",
       "      <td>False</td>\n",
       "      <td>norm</td>\n",
       "      <td>basic</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.670139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      exp_name  freeze_backbone preprocess_mode augment_mode  \\\n",
       "1       A2_finetune_norm_noaug            False            norm         none   \n",
       "3  C1_finetune_nonorm_basicaug            False         no_norm        basic   \n",
       "0    A1_linearprobe_norm_noaug             True            norm         none   \n",
       "2    B1_finetune_norm_basicaug            False            norm        basic   \n",
       "\n",
       "   epochs     lr  best_val_safe_acc  test_safe_acc  \n",
       "1      20  0.001           0.776042       0.744792  \n",
       "3      20  0.001           0.784722       0.717014  \n",
       "0      20  0.001           0.710069       0.710069  \n",
       "2      20  0.001           0.781250       0.670139  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments = [\n",
    "    # A1: supervised method 1 (linear probe) + norm + noaug\n",
    "    ExpConfig(exp_name=\"A1_linearprobe_norm_noaug\", freeze_backbone=True, preprocess_mode=\"norm\", augment_mode=\"none\"),\n",
    "    # A2: supervised method 2 (finetune) + norm + noaug\n",
    "    ExpConfig(exp_name=\"A2_finetune_norm_noaug\", freeze_backbone=False, preprocess_mode=\"norm\", augment_mode=\"none\"),\n",
    "    # B1: augmentation method (basic aug) + finetune + norm\n",
    "    ExpConfig(exp_name=\"B1_finetune_norm_basicaug\", freeze_backbone=False, preprocess_mode=\"norm\", augment_mode=\"basic\"),\n",
    "    # C1: preprocessing method (no_norm) + finetune + basic aug\n",
    "    ExpConfig(exp_name=\"C1_finetune_nonorm_basicaug\", freeze_backbone=False, preprocess_mode=\"no_norm\", augment_mode=\"basic\"),\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "for cfg in experiments:\n",
    "    all_results.append(run_one(cfg))\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_csv = OUT_DIR / \"tables\" / \"results_summary_min.csv\"\n",
    "results_df.to_csv(results_csv, index=False)\n",
    "print(\"Saved:\", results_csv)\n",
    "\n",
    "results_df[[\"exp_name\",\"freeze_backbone\",\"preprocess_mode\",\"augment_mode\",\"epochs\",\"lr\",\"best_val_safe_acc\",\"test_safe_acc\"]].sort_values(\n",
    "    \"test_safe_acc\", ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ebb05fb-e385-498f-8b49-51defe9ab8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved table: out_methods_minimum/tables/table_supervised_methods_min.csv\n",
      "Saved table: out_methods_minimum/tables/table_preprocessing_methods_min.csv\n",
      "Saved table: out_methods_minimum/tables/table_augmentation_methods_min.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_name</th>\n",
       "      <th>augment_mode</th>\n",
       "      <th>epochs</th>\n",
       "      <th>lr</th>\n",
       "      <th>test_safe_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2_finetune_norm_noaug</td>\n",
       "      <td>none</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.744792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B1_finetune_norm_basicaug</td>\n",
       "      <td>basic</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.670139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    exp_name augment_mode  epochs     lr  test_safe_acc\n",
       "1     A2_finetune_norm_noaug         none      20  0.001       0.744792\n",
       "2  B1_finetune_norm_basicaug        basic      20  0.001       0.670139"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_table(df: pd.DataFrame, name: str):\n",
    "    path = OUT_DIR / \"tables\" / f\"{name}.csv\"\n",
    "    df.to_csv(path, index=False)\n",
    "    print(\"Saved table:\", path)\n",
    "    return df\n",
    "\n",
    "t_supervised = results_df[results_df[\"exp_name\"].isin([\"A1_linearprobe_norm_noaug\",\"A2_finetune_norm_noaug\"])][\n",
    "    [\"exp_name\",\"freeze_backbone\",\"preprocess_mode\",\"augment_mode\",\"epochs\",\"lr\",\"test_safe_acc\"]\n",
    "]\n",
    "save_table(t_supervised, \"table_supervised_methods_min\")\n",
    "\n",
    "t_preproc = results_df[results_df[\"exp_name\"].isin([\"B1_finetune_norm_basicaug\",\"C1_finetune_nonorm_basicaug\"])][\n",
    "    [\"exp_name\",\"preprocess_mode\",\"augment_mode\",\"epochs\",\"lr\",\"test_safe_acc\"]\n",
    "]\n",
    "save_table(t_preproc, \"table_preprocessing_methods_min\")\n",
    "\n",
    "t_aug = results_df[results_df[\"exp_name\"].isin([\"A2_finetune_norm_noaug\",\"B1_finetune_norm_basicaug\"])][\n",
    "    [\"exp_name\",\"augment_mode\",\"epochs\",\"lr\",\"test_safe_acc\"]\n",
    "]\n",
    "save_table(t_aug, \"table_augmentation_methods_min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af65b0ad-1bfb-43ff-9d37-78c427316e33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
